{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f279ce28-8ea8-4ccd-9c63-b095228e175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoencoder\n",
    "import utils\n",
    "import mrrmse\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll import scope\n",
    "from ray import train, tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771a0f9e-ed59-4568-b6e8-4599c153eb0d",
   "metadata": {},
   "source": [
    "## Prepare data:\n",
    "#### Read joined data (pre + post treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d400fd1-c55b-4cef-b8dc-8c88b50e7c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lincs_joined_df = (107404, 1842)\n",
      "kaggle_joined_df = (602, 1841)\n",
      "test_joined_df = (255, 921)\n"
     ]
    }
   ],
   "source": [
    "lincs_joined_df = pd.read_parquet(\"data/lincs_pretreatment.parquet\")\n",
    "kaggle_joined_df = pd.read_parquet(\"data/kaggle_pretreatment.parquet\")\n",
    "test_joined_df = pd.read_parquet(\"data/test_pretreatment.parquet\")\n",
    "print(f\"lincs_joined_df = {lincs_joined_df.shape}\\nkaggle_joined_df = {kaggle_joined_df.shape}\\ntest_joined_df = {test_joined_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96590245-ca33-4fe3-8092-848b2286fb08",
   "metadata": {},
   "source": [
    "#### Kaggle provided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ec827ed-5c57-40df-ba5b-e2219b2e1e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de_train = (614, 18216)\n",
      "id_map = (255, 2)\n"
     ]
    }
   ],
   "source": [
    "de_train = pd.read_parquet('data/de_train.parquet')\n",
    "id_map = pd.read_csv('data/id_map.csv',index_col='id')\n",
    "print(f\"de_train = {de_train.shape}\\nid_map = {id_map.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c526082f-43a6-4ac2-b099-16f9426d067c",
   "metadata": {},
   "source": [
    "#### Define features of interest and sort data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "588df052-af79-4dc8-9349-93a02e923f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcriptome_cols = (18211,)\n",
      "landmark_cols = (918,)\n"
     ]
    }
   ],
   "source": [
    "features = ['cell_type', 'sm_name']\n",
    "multiindex_features = [(\"label\",'cell_type'),(\"label\",'sm_name')]\n",
    "\n",
    "transcriptome_cols = de_train.columns[5:]\n",
    "landmark_cols = kaggle_joined_df[\"post_treatment\"].columns\n",
    "print(f\"transcriptome_cols = {transcriptome_cols.shape}\\nlandmark_cols = {landmark_cols.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3cab5c9-b11b-44b3-a4d2-73d4b8a57bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique molecules = 1896.\n",
      "Number of unique cell types = 36.\n"
     ]
    }
   ],
   "source": [
    "unique_sm_name = pd.concat([lincs_joined_df[(\"label\",\"sm_name\")],kaggle_joined_df[(\"label\",\"sm_name\")]]).drop_duplicates().reset_index(drop=True)\n",
    "unique_cell_type = pd.concat([lincs_joined_df[(\"label\",\"cell_type\")],kaggle_joined_df[(\"label\",\"cell_type\")]]).drop_duplicates().reset_index(drop=True)\n",
    "print(f\"Number of unique molecules = {len(unique_sm_name)}.\\nNumber of unique cell types = {len(unique_cell_type)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe4c7429-9062-45a5-8c88-7b8c4eda8204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We only need to sort these two dataframes because they represent the same underlying dataset.\n",
    "de_train = de_train.query(\"~control\").sort_values(features)\n",
    "kaggle_joined_df = kaggle_joined_df.sort_values(multiindex_features)\n",
    "# Sanity check that these dfs align.\n",
    "genes_align = (kaggle_joined_df[\"post_treatment\"] == de_train[landmark_cols]).all(axis=None)\n",
    "labels_align = (kaggle_joined_df[\"label\"][features] == de_train[features]).all(axis=None)\n",
    "genes_align and labels_align"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa9dc95-c087-4b47-a1f4-1798d594a3b1",
   "metadata": {},
   "source": [
    "#### CV splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbcbabde-a608-441c-b942-67cf9f33aefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_cells_only_df = kaggle_joined_df[kaggle_joined_df[\"label\"][\"cell_type\"].isin([\"B cells\", \"Myeloid cells\"])][multiindex_features]\n",
    "len(eval_cells_only_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40d753c9-b552-4c04-a63e-4cbb4504ec34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold = 0 of shape (10, 2)\n",
      "fold = 1 of shape (10, 2)\n",
      "fold = 2 of shape (10, 2)\n"
     ]
    }
   ],
   "source": [
    "fold_to_eval_df = {}\n",
    "skf = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "for i,(t,v) in enumerate(skf.split(eval_cells_only_df)):\n",
    "    fold_to_eval_df[i] = eval_cells_only_df.iloc[v]\n",
    "\n",
    "for i, df in fold_to_eval_df.items():\n",
    "    print(f\"fold = {i} of shape {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "618b44f7-71a6-48e2-a2dd-0d396af97d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using fold 0 as validation set:\n",
      "Train data = (107994, 1843)\n",
      "Validation data = (12, 1841)\n"
     ]
    }
   ],
   "source": [
    "def make_mask(fold):\n",
    "    val = fold_to_eval_df[fold]\n",
    "    return kaggle_joined_df[(\"label\",\"sm_name\")].isin(val[(\"label\",\"sm_name\")]) & kaggle_joined_df[(\"label\",\"cell_type\")].isin(val[(\"label\",\"cell_type\")])\n",
    "\n",
    "print(\"Using fold 0 as validation set:\")\n",
    "print(f\"Train data = {pd.concat([kaggle_joined_df[~make_mask(0)],lincs_joined_df]).shape}\")\n",
    "print(f\"Validation data = {kaggle_joined_df[make_mask(0)].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c35d4cde-5324-4c0b-81a2-975c25d843ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(torch.nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(Translator,self).__init__()\n",
    "        # This will eventually be changed to a GNN\n",
    "        self.smiles_embed = torch.nn.Embedding(len(unique_sm_name), config[\"sm_emb_size\"])\n",
    "\n",
    "        # This needs to be able to handle out of dictionary\n",
    "        self.cell_embed = torch.nn.Embedding(len(unique_cell_type), config[\"cell_emb_size\"])\n",
    "\n",
    "        self.config = config\n",
    "        input_dim = config[\"sm_emb_size\"] + config[\"cell_emb_size\"] + config[\"latent_dim\"]\n",
    "        self.translation = utils.make_sequential(input_dim,config[\"hidden_dim\"],config[\"latent_dim\"],config[\"dropout\"])\n",
    "\n",
    "    def forward(self,inp,z):\n",
    "        sm_emb = self.smiles_embed(inp[\"sm_name\"])\n",
    "        ct_emb = self.cell_embed(inp[\"cell_type\"])\n",
    "        x = torch.cat((sm_emb, ct_emb, z), dim=1)\n",
    "        return self.translation(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40c3d8cf-fbde-4aeb-905d-77d647bb7621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNVAE(torch.nn.Module):\n",
    "    cell_type_map = {v: k for k,v in unique_cell_type.to_dict().items()}\n",
    "    sm_name_map = {v: k for k,v in unique_sm_name.to_dict().items()}\n",
    "    \n",
    "    def __init__(self,config):\n",
    "        super(RNVAE,self).__init__()\n",
    "        self.vae = autoencoder.AutoEncoder(target_dim=len(landmark_cols),config=config)\n",
    "        self.translator = Translator(config)\n",
    "\n",
    "    @classmethod\n",
    "    def make_input(cls, df):\n",
    "        ct = torch.tensor(df[(\"label\",\"cell_type\")].map(cls.cell_type_map).to_numpy())\n",
    "        sm = torch.tensor(df[(\"label\",\"sm_name\")].map(cls.sm_name_map).to_numpy())\n",
    "        pre = torch.tensor(df[\"pre_treatment\"].to_numpy(),dtype=torch.float32)\n",
    "        post = torch.tensor(df[\"post_treatment\"].to_numpy(),dtype=torch.float32)\n",
    "        \n",
    "        return [{\"cell_type\":ct[i],\n",
    "                \"sm_name\":sm[i],\n",
    "                \"pre_treatment\":pre[i],\n",
    "                \"post_treatment\":post[i]} for i in range(len(df))]\n",
    "\n",
    "    @classmethod\n",
    "    def make_test(cls,df):\n",
    "        ct = torch.tensor(df[(\"label\",\"cell_type\")].map(cls.cell_type_map).to_numpy())\n",
    "        sm = torch.tensor(df[(\"label\",\"sm_name\")].map(cls.sm_name_map).to_numpy())\n",
    "        pre = torch.tensor(df[\"pre_treatment\"].to_numpy(),dtype=torch.float32)\n",
    "        \n",
    "        return [{\"cell_type\":ct[i],\n",
    "                \"sm_name\":sm[i],\n",
    "                \"pre_treatment\":pre[i]} for i in range(len(df))]\n",
    "    \n",
    "    def forward(self,inp):\n",
    "        latent = self.vae.latent(inp[\"pre_treatment\"])\n",
    "        z_prime = self.translator(inp,latent[\"z\"])\n",
    "        x_hat = self.vae.decode(z_prime)\n",
    "        return {\"x_hat\":x_hat, \"mu\": latent[\"mu\"], \"log_var\":latent[\"log_var\"]}\n",
    "\n",
    "    def loss_function(self,fwd,inp):\n",
    "        return self.vae.loss_function(fwd,inp[\"post_treatment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0a1930d-433a-47d1-82b7-56637dbbf4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imputer(torch.nn.Module):\n",
    "    def __init__(self,config,rnvae):\n",
    "        super(Imputer,self).__init__()\n",
    "        self.impute_loss_weight = config[\"impute_loss_weight\"]\n",
    "        self.imp = utils.make_sequential(len(landmark_cols),config[\"hidden_dim\"],len(transcriptome_cols),config[\"dropout\"])\n",
    "        self.rnvae = rnvae\n",
    "\n",
    "    @classmethod\n",
    "    def make_input(cls, mask):\n",
    "        kg_df = kaggle_joined_df[mask]\n",
    "        trn_df = de_train[mask]\n",
    "        rninp = RNVAE.make_input(kg_df)\n",
    "        trm = trn_df[transcriptome_cols]\n",
    "        for i,inp in enumerate(rninp):\n",
    "            inp[\"transcriptome\"] = torch.tensor(trm.iloc[i].to_numpy(), dtype=torch.float)\n",
    "        return rninp\n",
    "\n",
    "    def forward(self,inp):\n",
    "        fwd = self.rnvae(inp)\n",
    "        trm = self.imp(fwd[\"x_hat\"])\n",
    "        fwd[\"transcriptome\"] = trm\n",
    "        return fwd\n",
    "\n",
    "    def loss_function(self,fwd,inp):\n",
    "        trm_loss = torch.nn.functional.mse_loss(fwd[\"transcriptome\"], inp[\"transcriptome\"])\n",
    "        lossdict = self.rnvae.loss_function(fwd,inp)\n",
    "        lossdict[\"loss\"] += self.impute_loss_weight*trm_loss\n",
    "        lossdict[\"Transcriptome_Loss\"] = trm_loss.detach()\n",
    "        return lossdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "292fd1f0-aea5-4f60-b943-4376884cc608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_type torch.int64\n",
      "sm_name torch.int64\n",
      "pre_treatment torch.float32\n",
      "post_treatment torch.float32\n"
     ]
    }
   ],
   "source": [
    "bsz = 512\n",
    "rnvae_inp = RNVAE.make_input(lincs_joined_df)\n",
    "for k, v in rnvae_inp[0].items():\n",
    "    print(k,v.dtype)\n",
    "rnvae_loader = torch.utils.data.DataLoader(rnvae_inp, batch_size=bsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fed2d2f9-716b-44e3-8379-95ea3ecdaa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_type torch.int64\n",
      "sm_name torch.int64\n",
      "pre_treatment torch.float32\n",
      "post_treatment torch.float32\n",
      "transcriptome torch.float32\n",
      "\n",
      "cell_type torch.int64\n",
      "sm_name torch.int64\n",
      "pre_treatment torch.float32\n",
      "post_treatment torch.float32\n",
      "transcriptome torch.float32\n",
      "cell_type torch.int64\n",
      "sm_name torch.int64\n",
      "pre_treatment torch.float32\n",
      "post_treatment torch.float32\n",
      "transcriptome torch.float32\n",
      "\n",
      "cell_type torch.int64\n",
      "sm_name torch.int64\n",
      "pre_treatment torch.float32\n",
      "post_treatment torch.float32\n",
      "transcriptome torch.float32\n",
      "cell_type torch.int64\n",
      "sm_name torch.int64\n",
      "pre_treatment torch.float32\n",
      "post_treatment torch.float32\n",
      "transcriptome torch.float32\n",
      "\n",
      "cell_type torch.int64\n",
      "sm_name torch.int64\n",
      "pre_treatment torch.float32\n",
      "post_treatment torch.float32\n",
      "transcriptome torch.float32\n"
     ]
    }
   ],
   "source": [
    "train_loaders = []\n",
    "eval_loaders = []\n",
    "for fold in fold_to_eval_df:\n",
    "    traind = Imputer.make_input(~make_mask(fold))\n",
    "    for k, v in traind[0].items():\n",
    "        print(k,v.dtype)\n",
    "    print()\n",
    "    train_loaders.append(torch.utils.data.DataLoader(traind, batch_size=bsz))\n",
    "    \n",
    "    evald = Imputer.make_input(make_mask(fold))\n",
    "    for k, v in evald[0].items():\n",
    "        print(k,v.dtype)\n",
    "    eval_loaders.append(torch.utils.data.DataLoader(evald, batch_size=len(evald)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81e19f66-3b3d-40fd-8733-0c6160b845b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(models):\n",
    "    def _epoch(model,opt,loader):\n",
    "        for batch in loader:\n",
    "            opt.zero_grad()\n",
    "            fwd = model(batch)\n",
    "            loss = model.loss_function(fwd,batch)[\"loss\"]\n",
    "            if torch.isnan(loss):\n",
    "                return loss.detach()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        return loss.detach()\n",
    "\n",
    "\n",
    "    loss = _epoch(models[\"rnvae\"],models[\"rnvae_opt\"],models[\"rnvae_loader\"])\n",
    "    if torch.isnan(loss):\n",
    "        return loss\n",
    "\n",
    "    loss = _epoch(models[\"imputer\"],models[\"impute_opt\"],models[\"train_loader\"])\n",
    "    if torch.isnan(loss):\n",
    "        return loss\n",
    "\n",
    "    imputer = models[\"imputer\"]\n",
    "    with torch.no_grad():\n",
    "        eval = next(iter(models[\"eval_loader\"]))\n",
    "        fwd = imputer(eval)\n",
    "        # The eval loss we wish to optimize is how well the model\n",
    "        # predicts the full transcriptome.\n",
    "        return imputer.loss_function(fwd,eval)[\"Transcriptome_Loss\"]\n",
    "\n",
    "def make_models(config, input_data, fold):\n",
    "    rnvae = RNVAE(config)\n",
    "    imputer = Imputer(config,rnvae)\n",
    "    return {\n",
    "        \"rnvae\": rnvae,\n",
    "        \"imputer\": imputer,\n",
    "        \"rnvae_opt\": torch.optim.Adam(rnvae.parameters(), lr=config[\"lr_rnvae\"]),\n",
    "        \"impute_opt\": torch.optim.Adam(imputer.parameters(), lr=config[\"lr_imputer\"]),\n",
    "        \"rnvae_loader\": input_data[\"rnvae_loader\"], # There is just one rnvae_loader shared across all folds\n",
    "        \"train_loader\": input_data[\"train_loaders\"][fold],\n",
    "        \"eval_loader\": input_data[\"eval_loaders\"][fold]\n",
    "    }\n",
    "    \n",
    "def train_model(config, input_data):    \n",
    "    all_models = []\n",
    "    for fold in input_data[\"fold_to_eval_df\"]:\n",
    "        all_models.append(make_models(config, input_data, fold))\n",
    "\n",
    "    for i in range(input_data[\"epochs\"]):\n",
    "        losses = []\n",
    "        for fold in input_data[\"fold_to_eval_df\"]:\n",
    "            losses.append(epoch(all_models[fold]))\n",
    "        \n",
    "        if np.any(np.isnan(losses)):\n",
    "            print({\"mse\": np.nan, \"done\": True})\n",
    "        else:\n",
    "            print({\"mse\": np.mean(losses)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6172cda-8d6e-4e80-8f1b-4908c94ec968",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "input_data = {\n",
    "    \"rnvae_loader\": rnvae_loader,\n",
    "    \"train_loaders\": train_loaders,\n",
    "    \"eval_loaders\": eval_loaders,\n",
    "    \"fold_to_eval_df\": fold_to_eval_df,\n",
    "    \"epochs\": epochs,\n",
    "}\n",
    "\n",
    "example_config = {\n",
    "    \"lr_rnvae\": 1e-3,\n",
    "    \"lr_imputer\": 1e-4,\n",
    "    \"dropout\": .1,\n",
    "    \"sm_emb_size\": 64,\n",
    "    \"cell_emb_size\": 32,\n",
    "    \"latent_dim\": 256,\n",
    "    \"hidden_dim\": 512,\n",
    "    \"kld_weight\": 1,\n",
    "    \"impute_loss_weight\": 2,\n",
    "}\n",
    "\n",
    "space = {\n",
    "    \"lr_rnvae\": hp.loguniform(\"lr_rnvae\", -10, -1),\n",
    "    \"lr_imputer\": hp.loguniform(\"lr_imputer\", -10, -1),\n",
    "    \"dropout\": hp.uniform(\"dropout\", 0, 1),\n",
    "    \"sm_emb_size\": scope.int(hp.qloguniform(\"sm_emb_size\", 0, 3, 1)),\n",
    "    \"cell_emb_size\": scope.int(hp.qloguniform(\"cell_emb_size\", 0, 3, 1)),\n",
    "    \"latent_dim\": scope.int(hp.qloguniform(\"latent_dim\", 0, 7, 1)),\n",
    "    \"hidden_dim\": scope.int(hp.qloguniform(\"hidden_dim\", 0, 7, 1)),\n",
    "    \"kld_weight\": hp.loguniform(\"kld_weight\", -2, 2),\n",
    "    \"impute_loss_weight\": hp.loguniform(\"impute_loss_weight\", -2, 2),\n",
    "}\n",
    "\n",
    "train_model(example_config,input_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
