{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f279ce28-8ea8-4ccd-9c63-b095228e175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoencoder\n",
    "import utils\n",
    "import mrrmse\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll import scope\n",
    "import ray\n",
    "from ray import train, tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771a0f9e-ed59-4568-b6e8-4599c153eb0d",
   "metadata": {},
   "source": [
    "## Prepare data:\n",
    "#### Read joined data (pre + post treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d400fd1-c55b-4cef-b8dc-8c88b50e7c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lincs_joined_df = (107404, 1842)\n",
      "kaggle_joined_df = (602, 1841)\n",
      "test_joined_df = (255, 921)\n"
     ]
    }
   ],
   "source": [
    "lincs_joined_df = pd.read_parquet(\"data/lincs_pretreatment.parquet\")\n",
    "kaggle_joined_df = pd.read_parquet(\"data/kaggle_pretreatment.parquet\")\n",
    "test_joined_df = pd.read_parquet(\"data/test_pretreatment.parquet\")\n",
    "print(f\"lincs_joined_df = {lincs_joined_df.shape}\\nkaggle_joined_df = {kaggle_joined_df.shape}\\ntest_joined_df = {test_joined_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96590245-ca33-4fe3-8092-848b2286fb08",
   "metadata": {},
   "source": [
    "#### Kaggle provided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ec827ed-5c57-40df-ba5b-e2219b2e1e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de_train = (614, 18216)\n",
      "id_map = (255, 2)\n"
     ]
    }
   ],
   "source": [
    "de_train = pd.read_parquet('data/de_train.parquet')\n",
    "id_map = pd.read_csv('data/id_map.csv',index_col='id')\n",
    "print(f\"de_train = {de_train.shape}\\nid_map = {id_map.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c526082f-43a6-4ac2-b099-16f9426d067c",
   "metadata": {},
   "source": [
    "#### Define features of interest and sort data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "588df052-af79-4dc8-9349-93a02e923f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcriptome_cols = (18211,)\n",
      "landmark_cols = (918,)\n"
     ]
    }
   ],
   "source": [
    "features = ['cell_type', 'sm_name']\n",
    "multiindex_features = [(\"label\",'cell_type'),(\"label\",'sm_name')]\n",
    "\n",
    "transcriptome_cols = de_train.columns[5:]\n",
    "landmark_cols = kaggle_joined_df[\"post_treatment\"].columns\n",
    "print(f\"transcriptome_cols = {transcriptome_cols.shape}\\nlandmark_cols = {landmark_cols.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3cab5c9-b11b-44b3-a4d2-73d4b8a57bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique molecules = 1896.\n",
      "Number of unique cell types = 36.\n"
     ]
    }
   ],
   "source": [
    "unique_sm_name = pd.concat([lincs_joined_df[(\"label\",\"sm_name\")],kaggle_joined_df[(\"label\",\"sm_name\")]]).drop_duplicates().reset_index(drop=True)\n",
    "unique_cell_type = pd.concat([lincs_joined_df[(\"label\",\"cell_type\")],kaggle_joined_df[(\"label\",\"cell_type\")]]).drop_duplicates().reset_index(drop=True)\n",
    "print(f\"Number of unique molecules = {len(unique_sm_name)}.\\nNumber of unique cell types = {len(unique_cell_type)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe4c7429-9062-45a5-8c88-7b8c4eda8204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We only need to sort these two dataframes because they represent the same underlying dataset.\n",
    "de_train = de_train.query(\"~control\").sort_values(features)\n",
    "kaggle_joined_df = kaggle_joined_df.sort_values(multiindex_features)\n",
    "# Sanity check that these dfs align.\n",
    "genes_align = (kaggle_joined_df[\"post_treatment\"] == de_train[landmark_cols]).all(axis=None)\n",
    "labels_align = (kaggle_joined_df[\"label\"][features] == de_train[features]).all(axis=None)\n",
    "genes_align and labels_align"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa9dc95-c087-4b47-a1f4-1798d594a3b1",
   "metadata": {},
   "source": [
    "#### CV splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbcbabde-a608-441c-b942-67cf9f33aefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_cells_only_df = kaggle_joined_df[kaggle_joined_df[\"label\"][\"cell_type\"].isin([\"B cells\", \"Myeloid cells\"])][multiindex_features]\n",
    "len(eval_cells_only_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40d753c9-b552-4c04-a63e-4cbb4504ec34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold = 0 of shape (10, 2)\n",
      "fold = 1 of shape (10, 2)\n",
      "fold = 2 of shape (10, 2)\n"
     ]
    }
   ],
   "source": [
    "fold_to_eval_df = {}\n",
    "skf = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "for i,(t,v) in enumerate(skf.split(eval_cells_only_df)):\n",
    "    fold_to_eval_df[i] = eval_cells_only_df.iloc[v]\n",
    "\n",
    "for i, df in fold_to_eval_df.items():\n",
    "    print(f\"fold = {i} of shape {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "618b44f7-71a6-48e2-a2dd-0d396af97d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using fold 0 as validation set:\n",
      "Train data = (107994, 1843)\n",
      "Validation data = (12, 1841)\n"
     ]
    }
   ],
   "source": [
    "def make_mask(fold):\n",
    "    val = fold_to_eval_df[fold]\n",
    "    return kaggle_joined_df[(\"label\",\"sm_name\")].isin(val[(\"label\",\"sm_name\")]) & kaggle_joined_df[(\"label\",\"cell_type\")].isin(val[(\"label\",\"cell_type\")])\n",
    "\n",
    "print(\"Using fold 0 as validation set:\")\n",
    "print(f\"Train data = {pd.concat([kaggle_joined_df[~make_mask(0)],lincs_joined_df]).shape}\")\n",
    "print(f\"Validation data = {kaggle_joined_df[make_mask(0)].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c35d4cde-5324-4c0b-81a2-975c25d843ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(torch.nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(Translator,self).__init__()\n",
    "        # This will eventually be changed to a GNN\n",
    "        self.smiles_embed = torch.nn.Embedding(len(unique_sm_name), config[\"sm_emb_size\"])\n",
    "\n",
    "        # This needs to be able to handle out of dictionary\n",
    "        self.cell_embed = torch.nn.Embedding(len(unique_cell_type), config[\"cell_emb_size\"])\n",
    "\n",
    "        self.config = config\n",
    "        input_dim = config[\"sm_emb_size\"] + config[\"cell_emb_size\"] + config[\"latent_dim\"]\n",
    "        self.translation = utils.make_sequential(input_dim,config[\"hidden_dim\"],config[\"latent_dim\"],config[\"dropout\"])\n",
    "\n",
    "    def forward(self,inp,z):\n",
    "        sm_emb = self.smiles_embed(inp[\"sm_name\"])\n",
    "        ct_emb = self.cell_embed(inp[\"cell_type\"])\n",
    "        x = torch.cat((sm_emb, ct_emb, z), dim=1)\n",
    "        return self.translation(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40c3d8cf-fbde-4aeb-905d-77d647bb7621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNVAE(torch.nn.Module):\n",
    "    cell_type_map = {v: k for k,v in unique_cell_type.to_dict().items()}\n",
    "    sm_name_map = {v: k for k,v in unique_sm_name.to_dict().items()}\n",
    "    \n",
    "    def __init__(self,config):\n",
    "        super(RNVAE,self).__init__()\n",
    "        self.vae = autoencoder.AutoEncoder(target_dim=len(landmark_cols),config=config)\n",
    "        self.translator = Translator(config)\n",
    "\n",
    "    @classmethod\n",
    "    def make_input(cls, df):\n",
    "        ct = torch.tensor(df[(\"label\",\"cell_type\")].map(cls.cell_type_map).to_numpy())\n",
    "        sm = torch.tensor(df[(\"label\",\"sm_name\")].map(cls.sm_name_map).to_numpy())\n",
    "        pre = torch.tensor(df[\"pre_treatment\"].to_numpy())\n",
    "        post = torch.tensor(df[\"post_treatment\"].to_numpy())\n",
    "        \n",
    "        return [{\"cell_type\":ct[i],\n",
    "                \"sm_name\":sm[i],\n",
    "                \"pre_treatment\":pre[i],\n",
    "                \"post_treatment\":post[i]} for i in range(len(df))]\n",
    "\n",
    "    @classmethod\n",
    "    def make_test(cls,df):\n",
    "        ct = torch.tensor(df[(\"label\",\"cell_type\")].map(cls.cell_type_map).to_numpy())\n",
    "        sm = torch.tensor(df[(\"label\",\"sm_name\")].map(cls.sm_name_map).to_numpy())\n",
    "        pre = torch.tensor(df[\"pre_treatment\"].to_numpy())\n",
    "        \n",
    "        return [{\"cell_type\":ct[i],\n",
    "                \"sm_name\":sm[i],\n",
    "                \"pre_treatment\":pre[i]} for i in range(len(df))]\n",
    "    \n",
    "    def forward(self,inp):\n",
    "        latent = self.vae.latent(inp[\"pre_treatment\"])\n",
    "        z_prime = self.translator(inp,latent[\"z\"])\n",
    "        x_hat = self.vae.decode(z_prime)\n",
    "        return {\"x_hat\":x_hat, \"mu\": latent[\"mu\"], \"log_var\":latent[\"log_var\"]}\n",
    "\n",
    "    def loss_function(self,fwd,inp):\n",
    "        return self.vae.loss_function(fwd,inp[\"post_treatment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0a1930d-433a-47d1-82b7-56637dbbf4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imputer(torch.nn.Module):\n",
    "    def __init__(self,config,rnvae):\n",
    "        super(Imputer,self).__init__()\n",
    "        self.impute_loss_weight = config[\"impute_loss_weight\"]\n",
    "        self.imp = utils.make_sequential(len(landmark_cols),config[\"hidden_dim\"],len(transcriptome_cols),config[\"dropout\"])\n",
    "        self.rnvae = rnvae\n",
    "\n",
    "    @classmethod\n",
    "    def make_input(cls, mask):\n",
    "        kg_df = kaggle_joined_df[mask]\n",
    "        trn_df = de_train[mask]\n",
    "        rninp = RNVAE.make_input(kg_df)\n",
    "        trm = trn_df[transcriptome_cols]\n",
    "        for i,inp in enumerate(rninp):\n",
    "            inp[\"transcriptome\"] = torch.tensor(trm.iloc[i].to_numpy(), dtype=torch.float)\n",
    "        return rninp\n",
    "\n",
    "    def forward(self,inp):\n",
    "        fwd = self.rnvae(inp)\n",
    "        trm = self.imp(fwd[\"x_hat\"])\n",
    "        fwd[\"transcriptome\"] = trm\n",
    "        return fwd\n",
    "\n",
    "    def loss_function(self,fwd,inp):\n",
    "        trm_loss = torch.nn.functional.mse_loss(fwd[\"transcriptome\"], inp[\"transcriptome\"])\n",
    "        lossdict = self.rnvae.loss_function(fwd,inp)\n",
    "        lossdict[\"loss\"] += self.impute_loss_weight*trm_loss\n",
    "        lossdict[\"Transcriptome_Loss\"] = trm_loss.detach()\n",
    "        return lossdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "292fd1f0-aea5-4f60-b943-4376884cc608",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnvaed = RNVAE.make_input(lincs_joined_df)\n",
    "rnvae_loader = torch.utils.data.DataLoader(rnvaed, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fed2d2f9-716b-44e3-8379-95ea3ecdaa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loaders = []\n",
    "eval_loaders = []\n",
    "for fold in fold_to_eval_df:\n",
    "    traind = Imputer.make_input(~make_mask(fold))\n",
    "    train_loaders.append(torch.utils.data.DataLoader(traind, batch_size=128))\n",
    "    \n",
    "    evald = Imputer.make_input(make_mask(fold))\n",
    "    eval_loaders.append(torch.utils.data.DataLoader(evald, batch_size=len(evald)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d25ac4df-0f14-49bf-a692-f8fbb0ec26ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mask = make_mask(0) | True\n",
    "all_train = Imputer.make_input(all_mask)\n",
    "all_loader = torch.utils.data.DataLoader(all_train, batch_size=32)\n",
    "\n",
    "submit_data = RNVAE.make_test(test_joined_df)\n",
    "submit_loader = torch.utils.data.DataLoader(submit_data, batch_size=len(submit_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81e19f66-3b3d-40fd-8733-0c6160b845b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"mse\"\n",
    "\n",
    "def do_epoch(models):\n",
    "    rnvae = models[\"rnvae\"]\n",
    "    imputer = models[\"imputer\"]\n",
    "    \n",
    "    rnvaeopt = models[\"rnvae_opt\"]\n",
    "    imputeopt = models[\"impute_opt\"]\n",
    "\n",
    "    for batch in models[\"rnvae_loader\"]:\n",
    "        rnvaeopt.zero_grad()\n",
    "        fwd = rnvae(batch)\n",
    "        loss = rnvae.loss_function(fwd,batch)[\"loss\"]\n",
    "        if torch.isnan(loss):\n",
    "            return loss.detach()\n",
    "        loss.backward()\n",
    "        rnvaeopt.step()\n",
    "\n",
    "    for batch in models[\"train_loader\"]:\n",
    "        imputeopt.zero_grad()\n",
    "        fwd = imputer(batch)\n",
    "        loss = imputer.loss_function(fwd,batch)[\"loss\"]\n",
    "        if torch.isnan(loss):\n",
    "            return loss.detach()\n",
    "        loss.backward()\n",
    "        imputeopt.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        eval = next(iter(models[\"eval_loader\"]))\n",
    "        fwd = imputer(batch)\n",
    "        # The eval loss we wish to optimize is how well the model\n",
    "        # predicts the full transcriptome.\n",
    "        return imputer.loss_function(fwd,batch)[\"Transcriptome_Loss\"]\n",
    "\n",
    "def make_models(config, input_data, fold):\n",
    "    rnvae = RNVAE(config)\n",
    "    imputer = Imputer(config,rnvae)\n",
    "    return {\n",
    "        \"rnvae\": rnvae,\n",
    "        \"imputer\": imputer,\n",
    "        \"rnvae_opt\": torch.optim.Adam(rnvae.parameters(), lr=config[\"lr_rnvae\"]),\n",
    "        \"impute_opt\": torch.optim.Adam(imputer.parameters(), lr=config[\"lr_imputer\"]),\n",
    "        \"rnvae_loader\": input_data[\"rnvae_loader\"], # There is just one rnvae_loader shared across all folds\n",
    "        \"train_loader\": input_data[\"train_loaders\"][fold],\n",
    "        \"eval_loader\": input_data[\"eval_loaders\"][fold]\n",
    "    }\n",
    "\n",
    "def train_model(config, input_data):\n",
    "    all_models = []\n",
    "    for fold in input_data[\"fold_to_eval_df\"]:\n",
    "        all_models.append(make_models(config, input_data, fold))\n",
    "\n",
    "    for i in range(input_data[\"epochs\"]):\n",
    "        losses = []\n",
    "        for fold in input_data[\"fold_to_eval_df\"]:\n",
    "            losses.append(do_epoch(all_models[fold]))\n",
    "        \n",
    "        if np.any(np.isnan(losses)):\n",
    "            train.report({metric: np.nan, \"done\": True})\n",
    "        else:\n",
    "            train.report({metric: np.mean(losses)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6172cda-8d6e-4e80-8f1b-4908c94ec968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-10-16 20:12:48</td></tr>\n",
       "<tr><td>Running for: </td><td>00:02:25.65        </td></tr>\n",
       "<tr><td>Memory:      </td><td>4.8/8.0 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 80.000: None | Iter 20.000: None | Iter 5.000: None<br>Logical resource usage: 0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                     </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_a0a18116</td><td style=\"text-align: right;\">           1</td><td>/Users/laurasisson/ray_results/train_model_2023-10-16_20-08-24/train_model_a0a18116_1_cell_emb_size=9,dropout=0.1328,hidden_dim=3,impute_loss_weight=2.8849,kld_weight=1.2408,latent_dim=10,lr_im_2023-10-16_20-10-23/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  cell_emb_size</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  hidden_dim</th><th style=\"text-align: right;\">  impute_loss_weight</th><th style=\"text-align: right;\">  kld_weight</th><th style=\"text-align: right;\">  latent_dim</th><th style=\"text-align: right;\">  lr_imputer</th><th style=\"text-align: right;\">  lr_rnvae</th><th style=\"text-align: right;\">  sm_emb_size</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_a0a18116</td><td>ERROR   </td><td>127.0.0.1:2356</td><td style=\"text-align: right;\">              9</td><td style=\"text-align: right;\">  0.13276</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">              2.8849</td><td style=\"text-align: right;\">     1.24084</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">   0.0135559</td><td style=\"text-align: right;\"> 0.0208805</td><td style=\"text-align: right;\">            8</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 20:10:24,203\tWARNING worker.py:2058 -- Warning: The actor ImplicitFunc is very large (92 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-10-16 20:11:17,827 E 2210 21502] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-10-16_20-08-24_899383_2187 is over 95% full, available space: 11412480000; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-10-16 20:11:27,922 E 2210 21502] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-10-16_20-08-24_899383_2187 is over 95% full, available space: 9386250240; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-10-16 20:11:37,927 E 2210 21502] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-10-16_20-08-24_899383_2187 is over 95% full, available space: 7283499008; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-10-16 20:11:48,026 E 2210 21502] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-10-16_20-08-24_899383_2187 is over 95% full, available space: 7334846464; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-10-16 20:11:58,123 E 2210 21502] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-10-16_20-08-24_899383_2187 is over 95% full, available space: 5202608128; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-10-16 20:12:08,133 E 2210 21502] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-10-16_20-08-24_899383_2187 is over 95% full, available space: 3038408704; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-10-16 20:12:18,142 E 2210 21502] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-10-16_20-08-24_899383_2187 is over 95% full, available space: 3257872384; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-10-16 20:12:28,241 E 2210 21502] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-10-16_20-08-24_899383_2187 is over 95% full, available space: 2703646720; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-10-16 20:12:38,247 E 2210 21502] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-10-16_20-08-24_899383_2187 is over 95% full, available space: 2847408128; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-10-16 20:12:48,344 E 2210 21502] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-10-16_20-08-24_899383_2187 is over 95% full, available space: 162406400; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "2023-10-16 20:12:48,750\tWARNING worker.py:2058 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff9ac088bb6c44fdceafd4171b01000000 Worker ID: aad8f32742075e451315eac90e184d8f83967e6af0d36c416fb4e052 Node ID: 69eee3f5a6fb2173c8cede466b57afe88dc4183b054650304014cdbf Worker IP address: 127.0.0.1 Worker port: 51014 Worker PID: 2356 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n",
      "2023-10-16 20:12:48,779\tERROR tune_controller.py:1502 -- Trial task failed for trial train_model_a0a18116\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/laurasisson/miniconda3/envs/rdenv/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/laurasisson/miniconda3/envs/rdenv/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/laurasisson/miniconda3/envs/rdenv/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/laurasisson/miniconda3/envs/rdenv/lib/python3.11/site-packages/ray/_private/worker.py\", line 2549, in get\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: ImplicitFunc\n",
      "\tactor_id: 9ac088bb6c44fdceafd4171b01000000\n",
      "\tpid: 2356\n",
      "\tnamespace: 539ad0e0-9c73-4e4e-9832-f7dd773bf602\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n",
      "2023-10-16 20:12:48,797\tERROR tune.py:1139 -- Trials did not complete: [train_model_a0a18116]\n",
      "2023-10-16 20:12:48,797\tINFO tune.py:1143 -- Total run time: 146.34 seconds (145.64 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "/Users/laurasisson/ray_results/train_model_2023-10-16_20-08-24/train_model_a0a18116_1_cell_emb_size=9,dropout=0.1328,hidden_dim=3,impute_loss_weight=2.8849,kld_weight=1.2408,latent_dim=10,lr_im_2023-10-16_20-10-23\n",
      "CONFIG: {'cell_emb_size': 9, 'dropout': 0.13276016694006587, 'hidden_dim': 3, 'impute_loss_weight': 2.8848952010691225, 'kld_weight': 1.2408397715503854, 'latent_dim': 10, 'lr_imputer': 0.013555912518663813, 'lr_rnvae': 0.020880461237649188, 'sm_emb_size': 8}\n",
      "METRICS: {'trial_id': 'a0a18116', 'date': '2023-10-16_20-10-29', 'timestamp': 1697501429, 'pid': 2356, 'hostname': 'Lauras-Air', 'node_ip': '127.0.0.1', 'config': {'cell_emb_size': 9, 'dropout': 0.13276016694006587, 'hidden_dim': 3, 'impute_loss_weight': 2.8848952010691225, 'kld_weight': 1.2408397715503854, 'latent_dim': 10, 'lr_imputer': 0.013555912518663813, 'lr_rnvae': 0.020880461237649188, 'sm_emb_size': 8}}\n"
     ]
    }
   ],
   "source": [
    "num_samples = 1\n",
    "epochs = 100\n",
    "\n",
    "input_data = {\n",
    "    \"rnvae_loader\": rnvae_loader,\n",
    "    \"train_loaders\": train_loaders,\n",
    "    \"eval_loaders\": eval_loaders,\n",
    "    \"fold_to_eval_df\": fold_to_eval_df,\n",
    "    \"epochs\": epochs,\n",
    "}\n",
    "\n",
    "space = {\n",
    "    \"lr_rnvae\": hp.loguniform(\"lr_rnvae\", -10, -1),\n",
    "    \"lr_imputer\": hp.loguniform(\"lr_imputer\", -10, -1),\n",
    "    \"dropout\": hp.uniform(\"dropout\", 0, 1),\n",
    "    \"sm_emb_size\": scope.int(hp.qloguniform(\"sm_emb_size\", 1, 3, 1)),\n",
    "    \"cell_emb_size\": scope.int(hp.qloguniform(\"cell_emb_size\", 1, 3, 1)),\n",
    "    \"latent_dim\": scope.int(hp.qloguniform(\"latent_dim\", 1, 7, 1)),\n",
    "    \"hidden_dim\": scope.int(hp.qloguniform(\"hidden_dim\", 1, 7, 1)),\n",
    "    \"kld_weight\": hp.loguniform(\"kld_weight\", -2, 2),\n",
    "    \"impute_loss_weight\": hp.loguniform(\"impute_loss_weight\", -2, 2),\n",
    "}\n",
    "\n",
    "mode = \"min\"\n",
    "hyperopt_search = HyperOptSearch(space, metric=metric, mode=mode)\n",
    "scheduler = ASHAScheduler(metric=metric, grace_period=5, mode=mode, max_t=epochs)\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_parameters(train_model, input_data=input_data),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        num_samples=num_samples,\n",
    "        search_alg=hyperopt_search,\n",
    "        scheduler=scheduler\n",
    "    ),\n",
    "    run_config=train.RunConfig(\n",
    "        failure_config=train.FailureConfig(fail_fast=False))\n",
    ")\n",
    "print(\"Starting raytune\")\n",
    "results = tuner.fit()\n",
    "print(\"DONE\")\n",
    "best_result = results.get_best_result(metric, mode=mode)\n",
    "print(best_result.path)\n",
    "print(\"CONFIG:\", best_result.config)\n",
    "print(\"METRICS:\", best_result.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbd0bd62-9204-45ce-85b7-134d46d1b298",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cell_emb_size': 9, 'dropout': 0.13276016694006587, 'hidden_dim': 3, 'impute_loss_weight': 2.8848952010691225, 'kld_weight': 1.2408397715503854, 'latent_dim': 10, 'lr_imputer': 0.013555912518663813, 'lr_rnvae': 0.020880461237649188, 'sm_emb_size': 8}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'training_iteration'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Because we trained the models on a cross-validation split, we want to train one final model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# across all data available.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28mrange\u001b[39m(best_result\u001b[38;5;241m.\u001b[39mmetrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_iteration\u001b[39m\u001b[38;5;124m\"\u001b[39m])):\n\u001b[1;32m     15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m do_epoch(best_models)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'training_iteration'"
     ]
    }
   ],
   "source": [
    "best_input_data = {\n",
    "    \"rnvae_loader\": rnvae_loader,\n",
    "    \"train_loaders\": [all_loader],\n",
    "    \"eval_loaders\": [all_loader],\n",
    "    \"fold_to_eval_df\": fold_to_eval_df,\n",
    "}\n",
    "\n",
    "best_models = make_models(best_result.config,best_input_data,0)\n",
    "print(best_result.config)\n",
    "# Because we trained the models on a cross-validation split, we want to train one final model\n",
    "# across all data available.\n",
    "\n",
    "loss = 0\n",
    "for _ in tqdm.tqdm(range(best_result.metrics[\"training_iteration\"])):\n",
    "    loss = do_epoch(best_models)\n",
    "print(loss)\n",
    "\n",
    "with torch.no_grad():\n",
    "    submitbatch = next(iter(submit_loader))\n",
    "    # This is the most elegant line of python ever written.\n",
    "    y_pred = best_models[\"imputer\"](submitbatch)[\"transcriptome\"]\n",
    "\n",
    "\n",
    "submission = pd.DataFrame(y_pred, columns=transcriptome_cols, index=id_map.index)\n",
    "display(submission)\n",
    "submission.to_csv('submissions/rnvae.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
