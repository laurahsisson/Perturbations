{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f279ce28-8ea8-4ccd-9c63-b095228e175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoencoder\n",
    "import utils\n",
    "import mrrmse\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771a0f9e-ed59-4568-b6e8-4599c153eb0d",
   "metadata": {},
   "source": [
    "## Prepare data:\n",
    "#### Read joined data (pre + post treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d400fd1-c55b-4cef-b8dc-8c88b50e7c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lincs_joined_df = (107404, 1842)\n",
      "kaggle_joined_df = (602, 1841)\n",
      "test_joined_df = (255, 921)\n"
     ]
    }
   ],
   "source": [
    "lincs_joined_df = pd.read_parquet(\"data/lincs_pretreatment.parquet\")\n",
    "kaggle_joined_df = pd.read_parquet(\"data/kaggle_pretreatment.parquet\")\n",
    "test_joined_df = pd.read_parquet(\"data/test_pretreatment.parquet\")\n",
    "print(f\"lincs_joined_df = {lincs_joined_df.shape}\\nkaggle_joined_df = {kaggle_joined_df.shape}\\ntest_joined_df = {test_joined_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96590245-ca33-4fe3-8092-848b2286fb08",
   "metadata": {},
   "source": [
    "#### Kaggle provided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ec827ed-5c57-40df-ba5b-e2219b2e1e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de_train = (614, 18216)\n",
      "id_map = (255, 2)\n"
     ]
    }
   ],
   "source": [
    "de_train = pd.read_parquet('data/de_train.parquet')\n",
    "id_map = pd.read_csv('data/id_map.csv',index_col='id')\n",
    "print(f\"de_train = {de_train.shape}\\nid_map = {id_map.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c526082f-43a6-4ac2-b099-16f9426d067c",
   "metadata": {},
   "source": [
    "#### Define features of interest and sort data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "588df052-af79-4dc8-9349-93a02e923f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcriptome_cols = (18211,)\n",
      "landmark_cols = (918,)\n"
     ]
    }
   ],
   "source": [
    "features = ['cell_type', 'sm_name']\n",
    "multiindex_features = [(\"label\",'cell_type'),(\"label\",'sm_name')]\n",
    "\n",
    "transcriptome_cols = de_train.columns[5:]\n",
    "landmark_cols = kaggle_joined_df[\"post_treatment\"].columns\n",
    "print(f\"transcriptome_cols = {transcriptome_cols.shape}\\nlandmark_cols = {landmark_cols.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3cab5c9-b11b-44b3-a4d2-73d4b8a57bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique molecules = 1896.\n",
      "Number of unique cell types = 36.\n"
     ]
    }
   ],
   "source": [
    "unique_sm_name = pd.concat([lincs_joined_df[(\"label\",\"sm_name\")],kaggle_joined_df[(\"label\",\"sm_name\")]]).drop_duplicates().reset_index(drop=True)\n",
    "unique_cell_type = pd.concat([lincs_joined_df[(\"label\",\"cell_type\")],kaggle_joined_df[(\"label\",\"cell_type\")]]).drop_duplicates().reset_index(drop=True)\n",
    "print(f\"Number of unique molecules = {len(unique_sm_name)}.\\nNumber of unique cell types = {len(unique_cell_type)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe4c7429-9062-45a5-8c88-7b8c4eda8204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We only need to sort these two dataframes because they represent the same underlying dataset.\n",
    "de_train = de_train.query(\"~control\").sort_values(features)\n",
    "kaggle_joined_df = kaggle_joined_df.sort_values(multiindex_features)\n",
    "# Sanity check that these dfs align.\n",
    "genes_align = (kaggle_joined_df[\"post_treatment\"] == de_train[landmark_cols]).all(axis=None)\n",
    "labels_align = (kaggle_joined_df[\"label\"][features] == de_train[features]).all(axis=None)\n",
    "genes_align and labels_align"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa9dc95-c087-4b47-a1f4-1798d594a3b1",
   "metadata": {},
   "source": [
    "#### CV splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbcbabde-a608-441c-b942-67cf9f33aefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_cells_only_df = kaggle_joined_df[kaggle_joined_df[\"label\"][\"cell_type\"].isin([\"B cells\", \"Myeloid cells\"])][multiindex_features]\n",
    "len(eval_cells_only_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d753c9-b552-4c04-a63e-4cbb4504ec34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold = 0 of shape (10, 2)\n",
      "fold = 1 of shape (10, 2)\n",
      "fold = 2 of shape (10, 2)\n"
     ]
    }
   ],
   "source": [
    "fold_to_eval_df = {}\n",
    "skf = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "for i,(t,v) in enumerate(skf.split(eval_cells_only_df)):\n",
    "    fold_to_eval_df[i] = eval_cells_only_df.iloc[v]\n",
    "\n",
    "for i, df in fold_to_eval_df.items():\n",
    "    print(f\"fold = {i} of shape {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "618b44f7-71a6-48e2-a2dd-0d396af97d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using fold 0 as validation set:\n",
      "Train data = (107994, 1843)\n",
      "Validation data = (12, 1841)\n"
     ]
    }
   ],
   "source": [
    "def make_mask(fold):\n",
    "    val = fold_to_eval_df[fold]\n",
    "    return kaggle_joined_df[(\"label\",\"sm_name\")].isin(val[(\"label\",\"sm_name\")]) & kaggle_joined_df[(\"label\",\"cell_type\")].isin(val[(\"label\",\"cell_type\")])\n",
    "\n",
    "print(\"Using fold 0 as validation set:\")\n",
    "print(f\"Train data = {pd.concat([kaggle_joined_df[~make_mask(0)],lincs_joined_df]).shape}\")\n",
    "print(f\"Validation data = {kaggle_joined_df[make_mask(0)].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c35d4cde-5324-4c0b-81a2-975c25d843ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(torch.nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(Translator,self).__init__()\n",
    "        # This will eventually be changed to a GNN\n",
    "        self.smiles_embed = torch.nn.Embedding(len(unique_sm_name), config[\"sm_emb_size\"])\n",
    "\n",
    "        # This needs to be able to handle out of dictionary\n",
    "        self.cell_embed = torch.nn.Embedding(len(unique_cell_type), config[\"cell_emb_size\"])\n",
    "\n",
    "        self.config = config\n",
    "        input_dim = config[\"sm_emb_size\"] + config[\"cell_emb_size\"] + config[\"latent_dim\"]\n",
    "        self.translation = utils.make_sequential(input_dim,config[\"hidden_dim\"],config[\"latent_dim\"],config[\"dropout\"])\n",
    "\n",
    "    def forward(self,inp,z):\n",
    "        sm_emb = self.smiles_embed(inp[\"sm_name\"])\n",
    "        ct_emb = self.cell_embed(inp[\"cell_type\"])\n",
    "        x = torch.cat((sm_emb, ct_emb, z), dim=1)\n",
    "        return self.translation(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "40c3d8cf-fbde-4aeb-905d-77d647bb7621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNVAE(torch.nn.Module):\n",
    "    cell_type_map = {v: k for k,v in unique_cell_type.to_dict().items()}\n",
    "    sm_name_map = {v: k for k,v in unique_sm_name.to_dict().items()}\n",
    "    \n",
    "    def __init__(self,config):\n",
    "        super(RNVAE,self).__init__()\n",
    "        self.vae = autoencoder.AutoEncoder(target_dim=len(landmark_cols),config=config)\n",
    "        self.translator = Translator(config)\n",
    "\n",
    "    @classmethod\n",
    "    def make_input(cls, df, disabletqdm=True):\n",
    "        ct = df[(\"label\",\"cell_type\")].map(cls.cell_type_map)\n",
    "        sm = df[(\"label\",\"sm_name\")].map(cls.sm_name_map)\n",
    "        return [{\"cell_type\":torch.tensor(ct.iloc[i]),\n",
    "                \"sm_name\":torch.tensor(sm.iloc[i]),\n",
    "                \"pre_treatment\":torch.tensor(df[\"pre_treatment\"].iloc[i].to_numpy(),dtype=torch.float),\n",
    "                \"post_treatment\":torch.tensor(df[\"post_treatment\"].iloc[i].to_numpy(),dtype=torch.float)} for i in tqdm.tqdm(range(len(df)),disable=disabletqdm)]\n",
    "        \n",
    "    def forward(self,inp):\n",
    "        assert inp[\"pre_treatment\"].shape == inp[\"post_treatment\"].shape\n",
    "        latent = self.vae.latent(inp[\"pre_treatment\"])\n",
    "        z_prime = self.translator(inp,latent[\"z\"])\n",
    "        x_hat = self.vae.decode(z_prime)\n",
    "        return {\"x_hat\":x_hat, \"mu\": latent[\"mu\"], \"log_var\":latent[\"log_var\"]}\n",
    "\n",
    "    def loss_function(self,fwd,inp):\n",
    "        return self.vae.loss_function(fwd,inp[\"post_treatment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e0a1930d-433a-47d1-82b7-56637dbbf4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imputer(torch.nn.Module):\n",
    "    def __init__(self,config,rnvae):\n",
    "        super(Imputer,self).__init__()\n",
    "        self.impute_loss_weight = config[\"impute_loss_weight\"]\n",
    "        self.imp = utils.make_sequential(len(landmark_cols),config[\"hidden_dim\"],len(transcriptome_cols),config[\"dropout\"])\n",
    "        self.rnvae = rnvae\n",
    "\n",
    "    @classmethod\n",
    "    def make_input(cls, mask):\n",
    "        kg_df = kaggle_joined_df[mask]\n",
    "        trn_df = de_train[mask]\n",
    "        rninp = RNVAE.make_input(kg_df)\n",
    "        trm = trn_df[transcriptome_cols]\n",
    "        for i,inp in enumerate(rninp):\n",
    "            inp[\"transcriptome\"] = torch.tensor(trm.iloc[i].to_numpy(), dtype=torch.float)\n",
    "        return rninp\n",
    "\n",
    "    def forward(self,inp):\n",
    "        fwd = self.rnvae(inp)\n",
    "        trm = self.imp(fwd[\"x_hat\"])\n",
    "        fwd[\"transcriptome\"] = trm\n",
    "        return fwd\n",
    "\n",
    "    def loss_function(self,fwd,inp):\n",
    "        trm_loss = torch.nn.functional.mse_loss(fwd[\"transcriptome\"], inp[\"transcriptome\"])\n",
    "        lossdict = self.rnvae.loss_function(fwd,inp)\n",
    "        lossdict[\"loss\"] += self.impute_loss_weight*trm_loss\n",
    "        lossdict[\"Transcriptome_Loss\"] = trm_loss.detach()\n",
    "        return lossdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9a7bf023-9bf9-48c9-a734-1b1ff1d6fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_config = {\n",
    "    \"sm_emb_size\": 64,\n",
    "    \"cell_emb_size\": 32,\n",
    "    \"latent_dim\": 256,\n",
    "    \"hidden_dim\": 512,\n",
    "    \"dropout\": .1,\n",
    "    \"kld_weight\": 1,\n",
    "    \"impute_loss_weight\": 2,\n",
    "}\n",
    "\n",
    "# inp = RNVAE.make_input(kaggle_joined_df[make_mask(0)])\n",
    "# rnvae = RNVAE(example_config)\n",
    "# fwd = rnvae(inp)\n",
    "# display(fwd[\"x_hat\"].shape)\n",
    "# rnvae.loss_function(fwd,inp)\n",
    "\n",
    "# inp = Imputer.make_input(make_mask(0))\n",
    "# imputer = Imputer(example_config,rnvae)\n",
    "# imputer.loss_function(fwd,inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "292fd1f0-aea5-4f60-b943-4376884cc608",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10000/10000 [00:46<00:00, 215.04it/s]\n"
     ]
    }
   ],
   "source": [
    "lincs_subset = lincs_joined_df.sample(10000)\n",
    "rnvae_inp = RNVAE.make_input(lincs_subset, disabletqdm=False)\n",
    "rnvae_loader = torch.utils.data.DataLoader(rnvae_inp, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fed2d2f9-716b-44e3-8379-95ea3ecdaa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_inp = Imputer.make_input(~make_mask(0))\n",
    "imputer_loader = torch.utils.data.DataLoader(imputer_inp, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e19f66-3b3d-40fd-8733-0c6160b845b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1):\n",
    "    for batch in rnvae_loader:\n",
    "        fwd = rnvae(batch)\n",
    "        print(\"RNVAE\",rnvae.loss_function(fwd,inp))\n",
    "\n",
    "    for batch in imputer_loader:\n",
    "        fwd = imputer(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
