{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f279ce28-8ea8-4ccd-9c63-b095228e175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoencoder\n",
    "import utils\n",
    "import mrrmse\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import random\n",
    "\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll import scope\n",
    "from ray import train, tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771a0f9e-ed59-4568-b6e8-4599c153eb0d",
   "metadata": {},
   "source": [
    "## Prepare data:\n",
    "#### Read joined data (pre + post treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d400fd1-c55b-4cef-b8dc-8c88b50e7c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lincs_joined_df = (107404, 1842)\n",
      "kaggle_joined_df = (602, 1841)\n",
      "test_joined_df = (255, 921)\n"
     ]
    }
   ],
   "source": [
    "lincs_joined_df = pd.read_parquet(\"data/lincs_pretreatment.parquet\")\n",
    "kaggle_joined_df = pd.read_parquet(\"data/kaggle_pretreatment.parquet\")\n",
    "test_joined_df = pd.read_parquet(\"data/test_pretreatment.parquet\")\n",
    "print(f\"lincs_joined_df = {lincs_joined_df.shape}\\nkaggle_joined_df = {kaggle_joined_df.shape}\\ntest_joined_df = {test_joined_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96590245-ca33-4fe3-8092-848b2286fb08",
   "metadata": {},
   "source": [
    "#### Kaggle provided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ec827ed-5c57-40df-ba5b-e2219b2e1e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de_train = (614, 18216)\n",
      "id_map = (255, 2)\n"
     ]
    }
   ],
   "source": [
    "de_train = pd.read_parquet('data/de_train.parquet')\n",
    "id_map = pd.read_csv('data/id_map.csv',index_col='id')\n",
    "print(f\"de_train = {de_train.shape}\\nid_map = {id_map.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c526082f-43a6-4ac2-b099-16f9426d067c",
   "metadata": {},
   "source": [
    "#### Define features of interest and sort data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "588df052-af79-4dc8-9349-93a02e923f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcriptome_cols = (18211,)\n",
      "landmark_cols = (918,)\n"
     ]
    }
   ],
   "source": [
    "features = ['cell_type', 'sm_name']\n",
    "multiindex_features = [(\"label\",'cell_type'),(\"label\",'sm_name')]\n",
    "\n",
    "transcriptome_cols = de_train.columns[5:]\n",
    "landmark_cols = kaggle_joined_df[\"post_treatment\"].columns\n",
    "print(f\"transcriptome_cols = {transcriptome_cols.shape}\\nlandmark_cols = {landmark_cols.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3cab5c9-b11b-44b3-a4d2-73d4b8a57bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique molecules = 1896.\n",
      "Number of unique cell types = 36.\n"
     ]
    }
   ],
   "source": [
    "unique_sm_name = pd.concat([lincs_joined_df[(\"label\",\"sm_name\")],kaggle_joined_df[(\"label\",\"sm_name\")]]).drop_duplicates().reset_index(drop=True)\n",
    "unique_cell_type = pd.concat([lincs_joined_df[(\"label\",\"cell_type\")],kaggle_joined_df[(\"label\",\"cell_type\")]]).drop_duplicates().reset_index(drop=True)\n",
    "print(f\"Number of unique molecules = {len(unique_sm_name)}.\\nNumber of unique cell types = {len(unique_cell_type)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe4c7429-9062-45a5-8c88-7b8c4eda8204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We only need to sort these two dataframes because they represent the same underlying dataset.\n",
    "de_train = de_train.query(\"~control\").sort_values(features)\n",
    "kaggle_joined_df = kaggle_joined_df.sort_values(multiindex_features)\n",
    "# Sanity check that these dfs align.\n",
    "genes_align = (kaggle_joined_df[\"post_treatment\"] == de_train[landmark_cols]).all(axis=None)\n",
    "labels_align = (kaggle_joined_df[\"label\"][features] == de_train[features]).all(axis=None)\n",
    "genes_align and labels_align"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa9dc95-c087-4b47-a1f4-1798d594a3b1",
   "metadata": {},
   "source": [
    "#### CV splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbcbabde-a608-441c-b942-67cf9f33aefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_cells_only_df = kaggle_joined_df[kaggle_joined_df[\"label\"][\"cell_type\"].isin([\"B cells\", \"Myeloid cells\"])][multiindex_features]\n",
    "len(eval_cells_only_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40d753c9-b552-4c04-a63e-4cbb4504ec34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold = 0 of shape (10, 2)\n",
      "fold = 1 of shape (10, 2)\n",
      "fold = 2 of shape (10, 2)\n"
     ]
    }
   ],
   "source": [
    "fold_to_eval_df = {}\n",
    "skf = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "for i,(t,v) in enumerate(skf.split(eval_cells_only_df)):\n",
    "    fold_to_eval_df[i] = eval_cells_only_df.iloc[v]\n",
    "\n",
    "for i, df in fold_to_eval_df.items():\n",
    "    print(f\"fold = {i} of shape {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "618b44f7-71a6-48e2-a2dd-0d396af97d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using fold 0 as validation set:\n",
      "Train data = (107994, 1843)\n",
      "Validation data = (12, 1841)\n"
     ]
    }
   ],
   "source": [
    "def make_mask(fold):\n",
    "    val = fold_to_eval_df[fold]\n",
    "    return kaggle_joined_df[(\"label\",\"sm_name\")].isin(val[(\"label\",\"sm_name\")]) & kaggle_joined_df[(\"label\",\"cell_type\")].isin(val[(\"label\",\"cell_type\")])\n",
    "\n",
    "print(\"Using fold 0 as validation set:\")\n",
    "print(f\"Train data = {pd.concat([kaggle_joined_df[~make_mask(0)],lincs_joined_df]).shape}\")\n",
    "print(f\"Validation data = {kaggle_joined_df[make_mask(0)].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c35d4cde-5324-4c0b-81a2-975c25d843ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(torch.nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(Translator,self).__init__()\n",
    "        # This will eventually be changed to a GNN\n",
    "        self.smiles_embed = torch.nn.Embedding(len(unique_sm_name), config[\"sm_emb_size\"])\n",
    "\n",
    "        # This needs to be able to handle out of dictionary\n",
    "        self.cell_embed = torch.nn.Embedding(len(unique_cell_type), config[\"cell_emb_size\"])\n",
    "\n",
    "        self.config = config\n",
    "        input_dim = config[\"sm_emb_size\"] + config[\"cell_emb_size\"] + config[\"latent_dim\"]\n",
    "        self.translation = utils.make_sequential(input_dim,config[\"hidden_dim\"],config[\"latent_dim\"],config[\"dropout\"])\n",
    "\n",
    "    def forward(self,inp,z):\n",
    "        sm_emb = self.smiles_embed(inp[\"sm_name\"])\n",
    "        ct_emb = self.cell_embed(inp[\"cell_type\"])\n",
    "        x = torch.cat((sm_emb, ct_emb, z), dim=1)\n",
    "        return self.translation(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40c3d8cf-fbde-4aeb-905d-77d647bb7621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNVAE(torch.nn.Module):\n",
    "    cell_type_map = {v: k for k,v in unique_cell_type.to_dict().items()}\n",
    "    sm_name_map = {v: k for k,v in unique_sm_name.to_dict().items()}\n",
    "    \n",
    "    def __init__(self,config):\n",
    "        super(RNVAE,self).__init__()\n",
    "        self.vae = autoencoder.AutoEncoder(target_dim=len(landmark_cols),config=config)\n",
    "        self.translator = Translator(config)\n",
    "\n",
    "    @classmethod\n",
    "    def make_input(cls, df):\n",
    "        ct = torch.tensor(df[(\"label\",\"cell_type\")].map(cls.cell_type_map).to_numpy())\n",
    "        sm = torch.tensor(df[(\"label\",\"sm_name\")].map(cls.sm_name_map).to_numpy())\n",
    "        pre = torch.tensor(df[\"pre_treatment\"].to_numpy(),dtype=torch.float32)\n",
    "        post = torch.tensor(df[\"post_treatment\"].to_numpy(),dtype=torch.float32)\n",
    "        \n",
    "        return [{\"cell_type\":ct[i],\n",
    "                \"sm_name\":sm[i],\n",
    "                \"pre_treatment\":pre[i],\n",
    "                \"post_treatment\":post[i]} for i in range(len(df))]\n",
    "\n",
    "    @classmethod\n",
    "    def make_test(cls,df):\n",
    "        ct = torch.tensor(df[(\"label\",\"cell_type\")].map(cls.cell_type_map).to_numpy())\n",
    "        sm = torch.tensor(df[(\"label\",\"sm_name\")].map(cls.sm_name_map).to_numpy())\n",
    "        pre = torch.tensor(df[\"pre_treatment\"].to_numpy(),dtype=torch.float32)\n",
    "        \n",
    "        return [{\"cell_type\":ct[i],\n",
    "                \"sm_name\":sm[i],\n",
    "                \"pre_treatment\":pre[i]} for i in range(len(df))]\n",
    "    \n",
    "    def forward(self,inp):\n",
    "        latent = self.vae.latent(inp[\"pre_treatment\"])\n",
    "        z_prime = self.translator(inp,latent[\"z\"])\n",
    "        x_hat = self.vae.decode(z_prime)\n",
    "        return {\"x_hat\":x_hat, \"mu\": latent[\"mu\"], \"log_var\":latent[\"log_var\"]}\n",
    "\n",
    "    def loss_function(self,fwd,inp):\n",
    "        return self.vae.loss_function(fwd,inp[\"post_treatment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0a1930d-433a-47d1-82b7-56637dbbf4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imputer(torch.nn.Module):\n",
    "    def __init__(self,config,rnvae):\n",
    "        super(Imputer,self).__init__()\n",
    "        self.impute_loss_weight = config[\"impute_loss_weight\"]\n",
    "        self.imp = utils.make_sequential(len(landmark_cols),config[\"hidden_dim\"],len(transcriptome_cols),config[\"dropout\"])\n",
    "        self.rnvae = rnvae\n",
    "\n",
    "    @classmethod\n",
    "    def make_input(cls, mask):\n",
    "        kg_df = kaggle_joined_df[mask]\n",
    "        trn_df = de_train[mask]\n",
    "        rninp = RNVAE.make_input(kg_df)\n",
    "        trm = trn_df[transcriptome_cols]\n",
    "        for i,inp in enumerate(rninp):\n",
    "            inp[\"transcriptome\"] = torch.tensor(trm.iloc[i].to_numpy(), dtype=torch.float)\n",
    "        return rninp\n",
    "\n",
    "    def forward(self,inp):\n",
    "        fwd = self.rnvae(inp)\n",
    "        trm = self.imp(fwd[\"x_hat\"])\n",
    "        fwd[\"transcriptome\"] = trm\n",
    "        return fwd\n",
    "\n",
    "    def loss_function(self,fwd,inp):\n",
    "        trm_loss = torch.nn.functional.mse_loss(fwd[\"transcriptome\"], inp[\"transcriptome\"])\n",
    "        lossdict = self.rnvae.loss_function(fwd,inp)\n",
    "        lossdict[\"loss\"] += self.impute_loss_weight*trm_loss\n",
    "        lossdict[\"Transcriptome_Loss\"] = trm_loss.detach()\n",
    "        return lossdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "292fd1f0-aea5-4f60-b943-4376884cc608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_type torch.int64 torch.Size([])\n",
      "sm_name torch.int64 torch.Size([])\n",
      "pre_treatment torch.float32 torch.Size([918])\n",
      "post_treatment torch.float32 torch.Size([918])\n"
     ]
    }
   ],
   "source": [
    "bsz = 512\n",
    "lincs_sample = lincs_joined_df.sample(10000)\n",
    "rnvae_inp = RNVAE.make_input(lincs_sample)\n",
    "\n",
    "for k, v in rnvae_inp[0].items():\n",
    "    print(k,v.dtype,v.shape)\n",
    "\n",
    "rnvae_loader = torch.utils.data.DataLoader(rnvae_inp, batch_size=bsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fed2d2f9-716b-44e3-8379-95ea3ecdaa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_type torch.int64\n",
      "sm_name torch.int64\n",
      "pre_treatment torch.float32\n",
      "post_treatment torch.float32\n",
      "transcriptome torch.float32\n",
      "\n",
      "cell_type torch.int64\n",
      "sm_name torch.int64\n",
      "pre_treatment torch.float32\n",
      "post_treatment torch.float32\n",
      "transcriptome torch.float32\n",
      "cell_type torch.int64\n",
      "sm_name torch.int64\n",
      "pre_treatment torch.float32\n",
      "post_treatment torch.float32\n",
      "transcriptome torch.float32\n",
      "\n",
      "cell_type torch.int64\n",
      "sm_name torch.int64\n",
      "pre_treatment torch.float32\n",
      "post_treatment torch.float32\n",
      "transcriptome torch.float32\n",
      "cell_type torch.int64\n",
      "sm_name torch.int64\n",
      "pre_treatment torch.float32\n",
      "post_treatment torch.float32\n",
      "transcriptome torch.float32\n",
      "\n",
      "cell_type torch.int64\n",
      "sm_name torch.int64\n",
      "pre_treatment torch.float32\n",
      "post_treatment torch.float32\n",
      "transcriptome torch.float32\n"
     ]
    }
   ],
   "source": [
    "train_loaders = []\n",
    "eval_loaders = []\n",
    "for fold in fold_to_eval_df:\n",
    "    traind = Imputer.make_input(~make_mask(fold))\n",
    "    for k, v in traind[0].items():\n",
    "        print(k,v.dtype)\n",
    "    print()\n",
    "    train_loaders.append(torch.utils.data.DataLoader(traind, batch_size=bsz))\n",
    "    \n",
    "    evald = Imputer.make_input(make_mask(fold))\n",
    "    for k, v in evald[0].items():\n",
    "        print(k,v.dtype)\n",
    "    eval_loaders.append(torch.utils.data.DataLoader(evald, batch_size=len(evald)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "81e19f66-3b3d-40fd-8733-0c6160b845b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(models):\n",
    "    def _epoch(model,opt,loader):\n",
    "        for batch in loader:\n",
    "            opt.zero_grad()\n",
    "            fwd = model(batch)\n",
    "            loss = model.loss_function(fwd,batch)[\"loss\"]\n",
    "            if torch.isnan(loss):\n",
    "                return loss.detach()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        return loss.detach()\n",
    "\n",
    "\n",
    "    loss = _epoch(models[\"rnvae\"],models[\"rnvae_opt\"],models[\"rnvae_loader\"])\n",
    "    if torch.isnan(loss):\n",
    "        return loss\n",
    "\n",
    "    loss = _epoch(models[\"imputer\"],models[\"impute_opt\"],models[\"train_loader\"])\n",
    "    if torch.isnan(loss):\n",
    "        return loss\n",
    "\n",
    "    imputer = models[\"imputer\"]\n",
    "    with torch.no_grad():\n",
    "        eval = next(iter(models[\"eval_loader\"]))\n",
    "        fwd = imputer(eval)\n",
    "        # The eval loss we wish to optimize is how well the model\n",
    "        # predicts the full transcriptome.\n",
    "        return imputer.loss_function(fwd,eval)[\"Transcriptome_Loss\"]\n",
    "\n",
    "def make_models(config, input_data, fold):\n",
    "    rnvae = RNVAE(config)\n",
    "    imputer = Imputer(config,rnvae)\n",
    "    return {\n",
    "        \"rnvae\": rnvae,\n",
    "        \"imputer\": imputer,\n",
    "        \"rnvae_opt\": torch.optim.Adam(rnvae.parameters(), lr=config[\"lr_rnvae\"]),\n",
    "        \"impute_opt\": torch.optim.Adam(imputer.parameters(), lr=config[\"lr_imputer\"]),\n",
    "        \"rnvae_loader\": input_data[\"rnvae_loader\"], # There is just one rnvae_loader shared across all folds\n",
    "        \"train_loader\": input_data[\"train_loaders\"][fold],\n",
    "        \"eval_loader\": input_data[\"eval_loaders\"][fold]\n",
    "    }\n",
    "\n",
    "def get_config(trial):\n",
    "    return {\n",
    "        \"lr_rnvae\": trial.suggest_float(\"lr_rnvae\", 1e-10,1e-1,log=True),\n",
    "        \"lr_imputer\": trial.suggest_float(\"lr_imputer\", 1e-10,1e-1,log=True),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0,1),\n",
    "        \"sm_emb_size\": trial.suggest_int(\"sm_emb_size\", 2,64,log=True),\n",
    "        \"cell_emb_size\": trial.suggest_int(\"cell_emb_size\", 2,64,log=True),\n",
    "        \"latent_dim\": trial.suggest_int(\"latent_dim\", 2,512,log=True),\n",
    "        \"hidden_dim\": trial.suggest_int(\"hidden_dim\", 2,512,log=True),\n",
    "        \"kld_weight\": trial.suggest_float(\"kld_weight\", 1e-1,1e1,log=True),\n",
    "        \"impute_loss_weight\": trial.suggest_float(\"impute_loss_weight\", 1e-1,1e1,log=True),\n",
    "    }\n",
    "\n",
    "def train_model(trial, input_data):    \n",
    "    config = get_config(trial)\n",
    "\n",
    "    all_models = []\n",
    "    for fold in input_data[\"fold_to_eval_df\"]:\n",
    "        all_models.append(make_models(config, input_data, fold))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "\n",
    "    loss = 0\n",
    "    for i in range(input_data[\"epochs\"]):\n",
    "        losses = []\n",
    "        for fold in input_data[\"fold_to_eval_df\"]:\n",
    "            losses.append(epoch(all_models[fold]))\n",
    "        \n",
    "        if np.any(np.isnan(losses)):\n",
    "            return np.nan\n",
    "\n",
    "        loss = np.mean(losses)\n",
    "        trial.report(loss, i)\n",
    "\n",
    "        print(trial,i,loss)\n",
    "        if trial.should_prune():\n",
    "            print(\"PRUNED\")\n",
    "            raise optuna.TrialPruned()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a6172cda-8d6e-4e80-8f1b-4908c94ec968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-22 15:37:18,909] A new study created in memory with name: no-name-d1d00f18-87f3-46b6-ba6d-8bc8bf1bd102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<optuna.trial._trial.Trial object at 0x28c30a690> 0 19.197311\n",
      "<optuna.trial._trial.Trial object at 0x28c30a690> 1 19.197908\n",
      "<optuna.trial._trial.Trial object at 0x28c30a690> 2 19.19666\n",
      "<optuna.trial._trial.Trial object at 0x28c30a690> 3 19.197485\n",
      "<optuna.trial._trial.Trial object at 0x28c30a690> 4 19.197641\n",
      "<optuna.trial._trial.Trial object at 0x28c30a690> 5 19.196627\n",
      "<optuna.trial._trial.Trial object at 0x28c30a690> 6 19.196775\n",
      "<optuna.trial._trial.Trial object at 0x28c30a690> 7 19.197819\n",
      "<optuna.trial._trial.Trial object at 0x28c30a690> 8 19.197535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-22 15:37:47,811] Trial 0 finished with value: 19.197330474853516 and parameters: {'lr_rnvae': 1.331898785390019e-05, 'lr_imputer': 1.3752003581111837e-09, 'dropout': 0.4859846340784424, 'sm_emb_size': 6, 'cell_emb_size': 24, 'latent_dim': 20, 'hidden_dim': 239, 'kld_weight': 2.973856066458786, 'impute_loss_weight': 0.18330012775068563}. Best is trial 0 with value: 19.197330474853516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<optuna.trial._trial.Trial object at 0x28c30a690> 9 19.19733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-10-22 15:37:50,594] Trial 1 failed with parameters: {'lr_rnvae': 0.0006659102228434802, 'lr_imputer': 0.05549624838966499, 'dropout': 0.7795568213566556, 'sm_emb_size': 4, 'cell_emb_size': 19, 'latent_dim': 86, 'hidden_dim': 274, 'kld_weight': 0.2069607690121021, 'impute_loss_weight': 9.72830678143174} because of the following error: The value nan is not acceptable.\n",
      "[W 2023-10-22 15:37:50,595] Trial 1 failed with value nan.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<optuna.trial._trial.Trial object at 0x2957f23d0> 0 19.19621\n",
      "<optuna.trial._trial.Trial object at 0x2957f23d0> 1 19.184694\n",
      "<optuna.trial._trial.Trial object at 0x2957f23d0> 2 19.173214\n",
      "<optuna.trial._trial.Trial object at 0x2957f23d0> 3 19.161776\n",
      "<optuna.trial._trial.Trial object at 0x2957f23d0> 4 19.150389\n",
      "<optuna.trial._trial.Trial object at 0x2957f23d0> 5 19.139053\n",
      "<optuna.trial._trial.Trial object at 0x2957f23d0> 6 19.127771\n",
      "<optuna.trial._trial.Trial object at 0x2957f23d0> 7 19.116552\n",
      "<optuna.trial._trial.Trial object at 0x2957f23d0> 8 19.105394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-22 15:37:58,905] Trial 2 finished with value: 19.094301223754883 and parameters: {'lr_rnvae': 1.2870229408877156e-07, 'lr_imputer': 0.0022470726566152844, 'dropout': 0.5263720953708545, 'sm_emb_size': 2, 'cell_emb_size': 9, 'latent_dim': 13, 'hidden_dim': 16, 'kld_weight': 5.592452296759948, 'impute_loss_weight': 0.7870108280769462}. Best is trial 2 with value: 19.094301223754883.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<optuna.trial._trial.Trial object at 0x2957f23d0> 9 19.094301\n",
      "<optuna.trial._trial.Trial object at 0x17d40f790> 0 19.197592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-22 15:38:02,333] Trial 3 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<optuna.trial._trial.Trial object at 0x17d40f790> 1 19.197874\n",
      "PRUNED\n",
      "<optuna.trial._trial.Trial object at 0x1138f6a50> 0 19.191257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-22 15:38:08,735] Trial 4 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<optuna.trial._trial.Trial object at 0x1138f6a50> 1 19.191158\n",
      "PRUNED\n",
      "<optuna.trial._trial.Trial object at 0x17d463190> 0 19.193192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-22 15:38:15,491] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<optuna.trial._trial.Trial object at 0x17d463190> 1 19.193089\n",
      "PRUNED\n",
      "<optuna.trial._trial.Trial object at 0x28c35d6d0> 0 19.22341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-22 15:38:17,998] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<optuna.trial._trial.Trial object at 0x28c35d6d0> 1 19.223192\n",
      "PRUNED\n",
      "<optuna.trial._trial.Trial object at 0x29589e7d0> 0 19.183413\n",
      "<optuna.trial._trial.Trial object at 0x29589e7d0> 1 19.16017\n",
      "<optuna.trial._trial.Trial object at 0x29589e7d0> 2 19.135866\n",
      "<optuna.trial._trial.Trial object at 0x29589e7d0> 3 19.111488\n",
      "<optuna.trial._trial.Trial object at 0x29589e7d0> 4 19.08589\n",
      "<optuna.trial._trial.Trial object at 0x29589e7d0> 5 19.06022\n",
      "<optuna.trial._trial.Trial object at 0x29589e7d0> 6 19.033773\n",
      "<optuna.trial._trial.Trial object at 0x29589e7d0> 7 18.954004\n",
      "<optuna.trial._trial.Trial object at 0x29589e7d0> 8 18.9282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-22 15:38:26,771] Trial 7 finished with value: 18.890403747558594 and parameters: {'lr_rnvae': 3.8182568660347965e-06, 'lr_imputer': 0.004806969840281675, 'dropout': 0.28207737288763135, 'sm_emb_size': 49, 'cell_emb_size': 13, 'latent_dim': 15, 'hidden_dim': 20, 'kld_weight': 0.33887984993910475, 'impute_loss_weight': 3.974090934259719}. Best is trial 7 with value: 18.890403747558594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<optuna.trial._trial.Trial object at 0x29589e7d0> 9 18.890404\n",
      "<optuna.trial._trial.Trial object at 0x295865390> 0 19.214434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-22 15:38:29,887] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<optuna.trial._trial.Trial object at 0x295865390> 1 19.213482\n",
      "PRUNED\n",
      "<optuna.trial._trial.Trial object at 0x28c2fa490> 0 19.192383\n",
      "<optuna.trial._trial.Trial object at 0x28c2fa490> 1 19.18372\n",
      "<optuna.trial._trial.Trial object at 0x28c2fa490> 2 19.173605\n",
      "<optuna.trial._trial.Trial object at 0x28c2fa490> 3 19.159813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-22 15:38:34,827] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<optuna.trial._trial.Trial object at 0x28c2fa490> 4 19.142134\n",
      "PRUNED\n",
      "DONE\n",
      "CONFIG: {'lr_rnvae': 3.8182568660347965e-06, 'lr_imputer': 0.004806969840281675, 'dropout': 0.28207737288763135, 'sm_emb_size': 49, 'cell_emb_size': 13, 'latent_dim': 15, 'hidden_dim': 20, 'kld_weight': 0.33887984993910475, 'impute_loss_weight': 3.974090934259719}\n",
      "METRICS: [18.890403747558594]\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "num_trials = 10\n",
    "epochs = 10\n",
    "\n",
    "input_data = {\n",
    "    \"rnvae_loader\": rnvae_loader,\n",
    "    \"train_loaders\": train_loaders,\n",
    "    \"eval_loaders\": eval_loaders,\n",
    "    \"fold_to_eval_df\": fold_to_eval_df,\n",
    "    \"epochs\": epochs,\n",
    "}\n",
    "\n",
    "example_config = {\n",
    "    \"lr_rnvae\": 1e-3,\n",
    "    \"lr_imputer\": 1e-4,\n",
    "    \"dropout\": .1,\n",
    "    \"sm_emb_size\": 64,\n",
    "    \"cell_emb_size\": 32,\n",
    "    \"latent_dim\": 256,\n",
    "    \"hidden_dim\": 512,\n",
    "    \"kld_weight\": 1,\n",
    "    \"impute_loss_weight\": 2,\n",
    "}\n",
    "\n",
    "objective = partial(train_model,input_data=input_data)\n",
    "study = optuna.create_study(direction=\"minimize\", pruner=optuna.pruners.SuccessiveHalvingPruner())  # Create a new study.\n",
    "study.optimize(objective, n_trials=num_trials)  # Invoke optimization of the objective function.\n",
    "\n",
    "print(\"DONE\")\n",
    "print(\"CONFIG:\", study.best_trial.params)\n",
    "print(\"METRICS:\", study.best_trial.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50f4549e-b92e-440b-b283-50badb0d090e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIG: {'lr_rnvae': 9.119854005489872e-09, 'lr_imputer': 2.961279890436606e-10, 'dropout': 0.4123583805945712, 'sm_emb_size': 24, 'cell_emb_size': 12, 'latent_dim': 396, 'hidden_dim': 157, 'kld_weight': 0.3061452078532722, 'impute_loss_weight': 0.34102487579912244}\n",
      "METRICS: [19.195880889892578]\n"
     ]
    }
   ],
   "source": [
    "study.best_trial\n",
    "print(\"CONFIG:\", study.best_trial.params)\n",
    "print(\"METRICS:\", study.best_trial.values)\n",
    "# trials = study.get_trials()\n",
    "# for t in trials:\n",
    "#     print(t.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "600ff319-7538-475c-8dbf-b7bc03faaaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mask = make_mask(0) | True\n",
    "all_train = Imputer.make_input(all_mask)\n",
    "all_loader = torch.utils.data.DataLoader(all_train, batch_size=32)\n",
    "\n",
    "submit_data = RNVAE.make_test(test_joined_df)\n",
    "submit_loader = torch.utils.data.DataLoader(submit_data, batch_size=len(submit_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3bcb3e65-60d8-4da6-89bf-131e675ac773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cell_emb_size': 1, 'dropout': 0.17459607590516624, 'hidden_dim': 439, 'impute_loss_weight': 0.3118326491123, 'kld_weight': 4.062189584858828, 'latent_dim': 20, 'lr_imputer': 0.001290806826201169, 'lr_rnvae': 0.0010711102093205497, 'sm_emb_size': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [02:26<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.1736)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1BG-AS1</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A2M-AS1</th>\n",
       "      <th>A2MP1</th>\n",
       "      <th>A4GALT</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AACS</th>\n",
       "      <th>AAGAB</th>\n",
       "      <th>AAK1</th>\n",
       "      <th>...</th>\n",
       "      <th>ZUP1</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.528672</td>\n",
       "      <td>0.318549</td>\n",
       "      <td>0.521696</td>\n",
       "      <td>0.771293</td>\n",
       "      <td>1.164450</td>\n",
       "      <td>0.884213</td>\n",
       "      <td>0.039088</td>\n",
       "      <td>0.527970</td>\n",
       "      <td>-0.104824</td>\n",
       "      <td>0.180595</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107548</td>\n",
       "      <td>0.202047</td>\n",
       "      <td>0.168787</td>\n",
       "      <td>0.420231</td>\n",
       "      <td>0.739610</td>\n",
       "      <td>0.506831</td>\n",
       "      <td>0.240892</td>\n",
       "      <td>0.206056</td>\n",
       "      <td>-0.084824</td>\n",
       "      <td>-0.098783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.030574</td>\n",
       "      <td>-0.025990</td>\n",
       "      <td>-0.019649</td>\n",
       "      <td>0.041366</td>\n",
       "      <td>-0.017743</td>\n",
       "      <td>-0.081546</td>\n",
       "      <td>-0.123232</td>\n",
       "      <td>0.013412</td>\n",
       "      <td>-0.080594</td>\n",
       "      <td>0.112765</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074695</td>\n",
       "      <td>-0.067768</td>\n",
       "      <td>-0.154886</td>\n",
       "      <td>0.006338</td>\n",
       "      <td>0.156259</td>\n",
       "      <td>0.106656</td>\n",
       "      <td>0.057608</td>\n",
       "      <td>0.048692</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>-0.189186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.523027</td>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.273987</td>\n",
       "      <td>0.232100</td>\n",
       "      <td>0.788171</td>\n",
       "      <td>1.206717</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.381870</td>\n",
       "      <td>-0.083118</td>\n",
       "      <td>0.142458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011714</td>\n",
       "      <td>0.137847</td>\n",
       "      <td>0.052237</td>\n",
       "      <td>0.385553</td>\n",
       "      <td>0.558164</td>\n",
       "      <td>0.430852</td>\n",
       "      <td>0.284110</td>\n",
       "      <td>0.172620</td>\n",
       "      <td>-0.097646</td>\n",
       "      <td>-0.050526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.178113</td>\n",
       "      <td>0.071593</td>\n",
       "      <td>0.302333</td>\n",
       "      <td>0.282079</td>\n",
       "      <td>0.409346</td>\n",
       "      <td>0.122760</td>\n",
       "      <td>-0.009732</td>\n",
       "      <td>0.240176</td>\n",
       "      <td>-0.141487</td>\n",
       "      <td>0.052558</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128297</td>\n",
       "      <td>0.098732</td>\n",
       "      <td>-0.013200</td>\n",
       "      <td>0.107470</td>\n",
       "      <td>0.324498</td>\n",
       "      <td>0.194461</td>\n",
       "      <td>0.168248</td>\n",
       "      <td>0.127013</td>\n",
       "      <td>-0.060557</td>\n",
       "      <td>-0.041977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000687</td>\n",
       "      <td>-0.073101</td>\n",
       "      <td>-0.075086</td>\n",
       "      <td>0.064975</td>\n",
       "      <td>0.122777</td>\n",
       "      <td>-0.040922</td>\n",
       "      <td>-0.125111</td>\n",
       "      <td>0.013967</td>\n",
       "      <td>-0.094423</td>\n",
       "      <td>0.113349</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145611</td>\n",
       "      <td>-0.079895</td>\n",
       "      <td>-0.190313</td>\n",
       "      <td>-0.027026</td>\n",
       "      <td>0.200238</td>\n",
       "      <td>0.141642</td>\n",
       "      <td>-0.009138</td>\n",
       "      <td>0.023725</td>\n",
       "      <td>0.097237</td>\n",
       "      <td>-0.227018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1.628841</td>\n",
       "      <td>0.780313</td>\n",
       "      <td>1.896007</td>\n",
       "      <td>2.646558</td>\n",
       "      <td>4.904253</td>\n",
       "      <td>3.166702</td>\n",
       "      <td>0.464417</td>\n",
       "      <td>1.569543</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>-0.110998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030858</td>\n",
       "      <td>0.838427</td>\n",
       "      <td>0.812316</td>\n",
       "      <td>1.221225</td>\n",
       "      <td>2.348658</td>\n",
       "      <td>1.466492</td>\n",
       "      <td>0.850378</td>\n",
       "      <td>0.304324</td>\n",
       "      <td>-0.248923</td>\n",
       "      <td>0.104876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.310764</td>\n",
       "      <td>0.046431</td>\n",
       "      <td>0.510666</td>\n",
       "      <td>0.601503</td>\n",
       "      <td>1.854848</td>\n",
       "      <td>0.558109</td>\n",
       "      <td>0.044957</td>\n",
       "      <td>0.061032</td>\n",
       "      <td>-0.282235</td>\n",
       "      <td>0.111371</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.311963</td>\n",
       "      <td>-0.007312</td>\n",
       "      <td>-0.150231</td>\n",
       "      <td>-0.264160</td>\n",
       "      <td>0.619928</td>\n",
       "      <td>0.109334</td>\n",
       "      <td>0.122755</td>\n",
       "      <td>-0.029426</td>\n",
       "      <td>-0.130031</td>\n",
       "      <td>-0.010530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1.764767</td>\n",
       "      <td>0.504572</td>\n",
       "      <td>0.873535</td>\n",
       "      <td>2.365860</td>\n",
       "      <td>10.343506</td>\n",
       "      <td>6.479660</td>\n",
       "      <td>0.502747</td>\n",
       "      <td>1.515960</td>\n",
       "      <td>0.444920</td>\n",
       "      <td>-0.819880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551924</td>\n",
       "      <td>0.135300</td>\n",
       "      <td>1.401836</td>\n",
       "      <td>0.654832</td>\n",
       "      <td>3.497616</td>\n",
       "      <td>1.634827</td>\n",
       "      <td>0.872020</td>\n",
       "      <td>0.341745</td>\n",
       "      <td>-0.901023</td>\n",
       "      <td>0.585574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>3.101876</td>\n",
       "      <td>1.583784</td>\n",
       "      <td>2.687714</td>\n",
       "      <td>4.606878</td>\n",
       "      <td>12.430525</td>\n",
       "      <td>7.394593</td>\n",
       "      <td>0.538450</td>\n",
       "      <td>2.536995</td>\n",
       "      <td>-0.288898</td>\n",
       "      <td>-0.163105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.201641</td>\n",
       "      <td>1.429180</td>\n",
       "      <td>1.243499</td>\n",
       "      <td>2.115982</td>\n",
       "      <td>5.056717</td>\n",
       "      <td>2.590979</td>\n",
       "      <td>1.249429</td>\n",
       "      <td>0.134950</td>\n",
       "      <td>-0.653481</td>\n",
       "      <td>0.165899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.770334</td>\n",
       "      <td>0.131853</td>\n",
       "      <td>1.368790</td>\n",
       "      <td>1.417684</td>\n",
       "      <td>4.453613</td>\n",
       "      <td>1.702669</td>\n",
       "      <td>0.313289</td>\n",
       "      <td>0.517054</td>\n",
       "      <td>-0.245450</td>\n",
       "      <td>0.160695</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.391975</td>\n",
       "      <td>0.320167</td>\n",
       "      <td>0.260397</td>\n",
       "      <td>-0.281400</td>\n",
       "      <td>1.500652</td>\n",
       "      <td>0.522748</td>\n",
       "      <td>0.539774</td>\n",
       "      <td>0.260404</td>\n",
       "      <td>-0.278045</td>\n",
       "      <td>0.389040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows × 18211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         A1BG  A1BG-AS1       A2M   A2M-AS1      A2MP1    A4GALT      AAAS  \\\n",
       "id                                                                           \n",
       "0    0.528672  0.318549  0.521696  0.771293   1.164450  0.884213  0.039088   \n",
       "1   -0.030574 -0.025990 -0.019649  0.041366  -0.017743 -0.081546 -0.123232   \n",
       "2    0.523027  0.228987  0.273987  0.232100   0.788171  1.206717  0.020542   \n",
       "3    0.178113  0.071593  0.302333  0.282079   0.409346  0.122760 -0.009732   \n",
       "4    0.000687 -0.073101 -0.075086  0.064975   0.122777 -0.040922 -0.125111   \n",
       "..        ...       ...       ...       ...        ...       ...       ...   \n",
       "250  1.628841  0.780313  1.896007  2.646558   4.904253  3.166702  0.464417   \n",
       "251  0.310764  0.046431  0.510666  0.601503   1.854848  0.558109  0.044957   \n",
       "252  1.764767  0.504572  0.873535  2.365860  10.343506  6.479660  0.502747   \n",
       "253  3.101876  1.583784  2.687714  4.606878  12.430525  7.394593  0.538450   \n",
       "254  0.770334  0.131853  1.368790  1.417684   4.453613  1.702669  0.313289   \n",
       "\n",
       "         AACS     AAGAB      AAK1  ...      ZUP1      ZW10    ZWILCH  \\\n",
       "id                                 ...                                 \n",
       "0    0.527970 -0.104824  0.180595  ... -0.107548  0.202047  0.168787   \n",
       "1    0.013412 -0.080594  0.112765  ... -0.074695 -0.067768 -0.154886   \n",
       "2    0.381870 -0.083118  0.142458  ...  0.011714  0.137847  0.052237   \n",
       "3    0.240176 -0.141487  0.052558  ... -0.128297  0.098732 -0.013200   \n",
       "4    0.013967 -0.094423  0.113349  ... -0.145611 -0.079895 -0.190313   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "250  1.569543  0.001372 -0.110998  ...  0.030858  0.838427  0.812316   \n",
       "251  0.061032 -0.282235  0.111371  ... -0.311963 -0.007312 -0.150231   \n",
       "252  1.515960  0.444920 -0.819880  ...  0.551924  0.135300  1.401836   \n",
       "253  2.536995 -0.288898 -0.163105  ... -0.201641  1.429180  1.243499   \n",
       "254  0.517054 -0.245450  0.160695  ... -0.391975  0.320167  0.260397   \n",
       "\n",
       "        ZWINT      ZXDA      ZXDB      ZXDC    ZYG11B       ZYX     ZZEF1  \n",
       "id                                                                         \n",
       "0    0.420231  0.739610  0.506831  0.240892  0.206056 -0.084824 -0.098783  \n",
       "1    0.006338  0.156259  0.106656  0.057608  0.048692  0.077000 -0.189186  \n",
       "2    0.385553  0.558164  0.430852  0.284110  0.172620 -0.097646 -0.050526  \n",
       "3    0.107470  0.324498  0.194461  0.168248  0.127013 -0.060557 -0.041977  \n",
       "4   -0.027026  0.200238  0.141642 -0.009138  0.023725  0.097237 -0.227018  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "250  1.221225  2.348658  1.466492  0.850378  0.304324 -0.248923  0.104876  \n",
       "251 -0.264160  0.619928  0.109334  0.122755 -0.029426 -0.130031 -0.010530  \n",
       "252  0.654832  3.497616  1.634827  0.872020  0.341745 -0.901023  0.585574  \n",
       "253  2.115982  5.056717  2.590979  1.249429  0.134950 -0.653481  0.165899  \n",
       "254 -0.281400  1.500652  0.522748  0.539774  0.260404 -0.278045  0.389040  \n",
       "\n",
       "[255 rows x 18211 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_input_data = {\n",
    "    \"rnvae_loader\": rnvae_loader,\n",
    "    \"train_loaders\": [all_loader],\n",
    "    \"eval_loaders\": [all_loader],\n",
    "    \"fold_to_eval_df\": fold_to_eval_df,\n",
    "}\n",
    "\n",
    "best_models = make_models(best_result.config,best_input_data,0)\n",
    "print(best_result.config)\n",
    "# Because we trained the models on a cross-validation split, we want to train one final model\n",
    "# across all data available.\n",
    "\n",
    "loss = 0\n",
    "for _ in tqdm.tqdm(range(best_result.metrics[\"training_iteration\"])):\n",
    "    loss = epoch(best_models)\n",
    "print(loss)\n",
    "\n",
    "with torch.no_grad():\n",
    "    submitbatch = next(iter(submit_loader))\n",
    "    # This is the most elegant line of python ever written.\n",
    "    y_pred = best_models[\"imputer\"](submitbatch)[\"transcriptome\"]\n",
    "\n",
    "\n",
    "submission = pd.DataFrame(y_pred, columns=transcriptome_cols, index=id_map.index)\n",
    "display(submission)\n",
    "submission.to_csv('submissions/rnvae.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
